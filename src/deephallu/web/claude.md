# 项目

## 1. 项目背景与目标
近年来，视觉语言模型（Vision-Language Models, VLMs）在图文理解与生成中取得了巨大进展，但“幻觉”问题（模型生成与输入不一致的信息）仍是研究和应用中的核心挑战。
本系统旨在构建一个交互式平台，帮助研究人员：
- 分析模型在推理过程中的注意力机制与生成分布。
- 可视化“幻觉”现象发生时的因果注意力（causal attention）和预测分布。
- 直观呈现输入图片与文本之间的关联性。

## 2. 系统总体架构
系统采用 前后端分离架构：
- 前端：Next.js 实现交互界面与可视化。
- 后端：Python FastAPI 提供模型推理服务与数据接口。
- 模型：支持多种视觉语言模型（可配置，主要为LLaVA Next 系列模型）。
- 数据集：VQA v2、MME 等常见多模态评测数据集（可配置）。

## 3. 功能需求
### 3.1 数据输入
- 用户可通过前端上传图片（jpg/png/jpeg）。
- 用户可选择预置数据集（VQA v2、MME）。
- 用户可输入或选择问题（text query）。

### 3.2 模型选择与运行
- 用户可选择目标模型进行推理。
- 系统调用后端，运行模型推理。
- 后端返回以下信息：
  - Causal Attention 矩阵
  - Token-level Next Token Prediction 分布
  - 图像 Patch 与文本 Token 对齐结果

### 3.3 可视化功能
- Token 悬浮交互：用户将鼠标悬停在某个文本 token 上，界面动态显示：
    - 该 token 与前序文本、图像 patch 的注意力分布（热力图/透明度可视化）。
    - 该 token 的 下一词预测分布（Top-K 概率条形图）。
- Attention Threshold 高亮：
    - 当某些图像 patch 的注意力值超过设定阈值时，该 patch 将“抬升”或加亮显示。
    - 交互对齐展示：
        - 图像和文本之间的 attention 权重联动显示。
### 3.4 系统配置与参数
- 阈值可调节：用户可调节高亮阈值（如 0.2/0.5）。
- Top-K 预测数：用户可选择查看前 K 个预测结果（默认 Top-5）。
- 模型参数配置（max length, temperature 等）。

## 4. 非功能需求
### 4.1 性能
- 前端响应延迟 < 200ms（交互级别），模型推理根据硬件资源优化。
### 4.2 兼容性
- 支持 Chrome/Edge/Firefox 浏览器。
### 4.3 可扩展性
- 系统应支持未来接入更多数据集和模型。
### 4.4 可视化体验
- 界面交互流畅，attention 热力图与图像 patch 高亮效果需自然过渡。

## 5. 技术选型
### 5.1 前端
- 框架：Next.js
- 可视化：D3.js / Three.js（用于动态 attention 高亮）
- UI 库：Tailwind CSS / shadcn/ui
### 5.2 后端
- 框架：FastAPI
- 深度学习框架：PyTorch
- 模型调用：HuggingFace Transformers / OpenAI API（视情况）
- 数据存储：文件系统存储上传图片

## 6. 交互流程示例
- 用户进入系统
用户进入系统 → 上传图片或选择数据集样例
- 用户输入问题
用户输入问题 → 选择模型
- 系统运行模型
系统运行模型 → 返回答案 + Attention + Token预测
- 用户悬浮在 Token
用户悬浮在 Token → 动态可视化 Attention 分布 & Next Token 分布
- 用户调整阈值
用户调整阈值 → 图像 patch 高亮实时更新

## 7. 预期成果
- 一个可交互的网页平台。
- 支持多种数据输入与模型选择。
- 提供直观的 Attention 与预测分布可视化。
- 辅助研究人员分析 VLM 幻觉问题的工具。