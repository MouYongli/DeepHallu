"""
LlavaNext Image Processor Analysis
ä»åŸå§‹å›¾åƒ (1100, 808) åˆ° pixel_values [1, 5, 3, 336, 336] çš„å…¨è¿‡ç¨‹åˆ†æ

è¿™ä¸ªæ–‡ä»¶è¯¦ç»†å±•ç¤ºäº†LlavaNextImageProcessorå¦‚ä½•å¤„ç†å›¾åƒçš„å®Œæ•´æµç¨‹
"""

import os
os.environ["HF_HOME"] = "/DATA2/HuggingFace"

import numpy as np
import torch
from PIL import Image
from transformers import LlavaNextProcessor
import matplotlib.pyplot as plt
from typing import List, Tuple


class ImageProcessorAnalysis:
    """åˆ†æLlavaNextå›¾åƒå¤„ç†å™¨çš„å®Œæ•´æµç¨‹"""
    
    def __init__(self):
        self.processor = LlavaNextProcessor.from_pretrained("llava-hf/llava-v1.6-mistral-7b-hf")
        self.image_processor = self.processor.image_processor
        
    def analyze_full_pipeline(self, image_path_or_pil: str | Image.Image):
        """å®Œæ•´åˆ†æä»åŸå§‹å›¾åƒåˆ°æœ€ç»ˆtensorçš„å¤„ç†æµç¨‹"""
        
        # Step 1: åŠ è½½åŸå§‹å›¾åƒ
        if isinstance(image_path_or_pil, str):
            image = Image.open(image_path_or_pil)
        else:
            image = image_path_or_pil
            
        print("=" * 80)
        print("LlavaNext Image Processing Pipeline Analysis")
        print("=" * 80)
        
        # Step 2: åŸå§‹å›¾åƒä¿¡æ¯
        print(f"\nğŸ“¸ Step 1: Original Image Info")
        print(f"   Size: {image.size} (width x height)")
        print(f"   Mode: {image.mode}")
        print(f"   Format: {getattr(image, 'format', 'N/A')}")
        
        # Step 3: åˆ†æimage processoré…ç½®
        self._analyze_processor_config()
        
        # Step 4: æœ€ä½³åˆ†è¾¨ç‡é€‰æ‹©
        best_resolution = self._analyze_resolution_selection(image.size)
        
        # Step 5: å¤šå°ºåº¦å¤„ç†
        processed_results = self._analyze_multiscale_processing(image)
        
        # Step 6: æœ€ç»ˆè¾“å‡ºåˆ†æ
        self._analyze_final_output(processed_results)
        
        return processed_results
    
    def _analyze_processor_config(self):
        """åˆ†æå›¾åƒå¤„ç†å™¨é…ç½®"""
        print(f"\nâš™ï¸  Step 2: Image Processor Configuration")
        print(f"   Do resize: {getattr(self.image_processor, 'do_resize', 'N/A')}")
        print(f"   Size: {getattr(self.image_processor, 'size', 'N/A')}")
        print(f"   Image grid pinpoints: {getattr(self.image_processor, 'image_grid_pinpoints', 'N/A')}")
        print(f"   Resample: {getattr(self.image_processor, 'resample', 'N/A')}")
        print(f"   Do center crop: {getattr(self.image_processor, 'do_center_crop', 'N/A')}")
        print(f"   Crop size: {getattr(self.image_processor, 'crop_size', 'N/A')}")
        print(f"   Do rescale: {getattr(self.image_processor, 'do_rescale', 'N/A')}")
        print(f"   Rescale factor: {getattr(self.image_processor, 'rescale_factor', 'N/A')}")
        print(f"   Do normalize: {getattr(self.image_processor, 'do_normalize', 'N/A')}")
        print(f"   Image mean: {getattr(self.image_processor, 'image_mean', 'N/A')}")
        print(f"   Image std: {getattr(self.image_processor, 'image_std', 'N/A')}")
        print(f"   Do pad: {getattr(self.image_processor, 'do_pad', 'N/A')}")
        print(f"   Do convert RGB: {getattr(self.image_processor, 'do_convert_rgb', 'N/A')}")
        
        if hasattr(self.image_processor, 'image_grid_pinpoints'):
            print(f"   Grid pinpoints: {len(self.image_processor.image_grid_pinpoints)} resolutions")
            print(f"   Grid pinpoints: {self.image_processor.image_grid_pinpoints[:5]}...")
    
    def _analyze_resolution_selection(self, original_size: Tuple[int, int]) -> Tuple[int, int]:
        """åˆ†ææœ€ä½³åˆ†è¾¨ç‡é€‰æ‹©è¿‡ç¨‹"""
        print(f"\nğŸ¯ Step 3: Best Resolution Selection")
        
        # è·å–image_grid_pinpoints
        if hasattr(self.image_processor, 'image_grid_pinpoints'):
            grid_pinpoints = self.image_processor.image_grid_pinpoints
            print(f"   Available resolutions: {len(grid_pinpoints)}")
            
            # æ¨¡æ‹Ÿselect_best_resolutioné€»è¾‘
            width, height = original_size
            original_area = width * height
            best_resolution = None
            min_wasted_resolution = float('inf')
            
            print(f"   Original size: {width} x {height} (area: {original_area})")
            
            for i, (pin_width, pin_height) in enumerate(grid_pinpoints):
                # è®¡ç®—å¦‚ä½•ç¼©æ”¾åŸå§‹å›¾åƒä»¥é€‚åº”è¿™ä¸ªåˆ†è¾¨ç‡
                scale = min(pin_width / width, pin_height / height)
                scaled_width = int(width * scale)
                scaled_height = int(height * scale)
                wasted_resolution = (pin_width * pin_height) - (scaled_width * scaled_height)
                
                if wasted_resolution < min_wasted_resolution:
                    min_wasted_resolution = wasted_resolution
                    best_resolution = (pin_height, pin_width)  # æ³¨æ„ï¼šè¿”å›æ ¼å¼æ˜¯(height, width)
                    best_scale = scale
                
                if i < 3:  # æ˜¾ç¤ºå‰å‡ ä¸ªè®¡ç®—è¿‡ç¨‹
                    print(f"   Candidate {pin_width}x{pin_height}: scale={scale:.3f}, "
                          f"scaled={scaled_width}x{scaled_height}, wasted={wasted_resolution}")
            
            print(f"   âœ… Best resolution: {best_resolution} (scale: {best_scale:.3f})")
            print(f"   âœ… Minimum wasted pixels: {min_wasted_resolution}")
            
            return best_resolution
        else:
            # å¦‚æœæ²¡æœ‰grid_pinpointsï¼Œä½¿ç”¨é»˜è®¤çš„336x336
            print(f"   Using default size: 336x336")
            return (336, 336)
    
    def _analyze_multiscale_processing(self, image: Image.Image) -> dict:
        """åˆ†æå¤šå°ºåº¦å¤„ç†è¿‡ç¨‹"""
        print(f"\nğŸ”„ Step 4: Multi-scale Processing")
        
        # ç›´æ¥è°ƒç”¨image_processorè·å–ç»“æœ
        processed_inputs = self.image_processor(image, return_tensors="pt")
        pixel_values = processed_inputs["pixel_values"]
        
        print(f"   Final tensor shape: {pixel_values.shape}")
        
        if len(pixel_values.shape) == 5:
            batch, num_scales, channels, height, width = pixel_values.shape
            print(f"   Batch size: {batch}")
            print(f"   Number of scales: {num_scales}")
            print(f"   Channels: {channels}")
            print(f"   Height: {height}")
            print(f"   Width: {width}")
            
            print(f"\n   ğŸ’¡ Multi-scale explanation:")
            print(f"   - LlavaNext uses {num_scales} different scales for better feature extraction")
            print(f"   - Each scale captures different levels of detail")
            print(f"   - Base resolution: {height}x{width}")
            
            # åˆ†ææ¯ä¸ªå°ºåº¦çš„ç»Ÿè®¡ä¿¡æ¯
            for scale_idx in range(num_scales):
                scale_tensor = pixel_values[0, scale_idx]  # [C, H, W]
                mean_val = scale_tensor.mean().item()
                std_val = scale_tensor.std().item()
                min_val = scale_tensor.min().item()
                max_val = scale_tensor.max().item()
                
                print(f"   Scale {scale_idx}: mean={mean_val:.3f}, std={std_val:.3f}, "
                      f"range=[{min_val:.3f}, {max_val:.3f}]")
        
        # è¿”å›å¤„ç†ç»“æœå’Œé¢å¤–ä¿¡æ¯
        return {
            "pixel_values": pixel_values,
            "image_sizes": processed_inputs.get("image_sizes"),
            "processed_inputs": processed_inputs
        }
    
    def _analyze_final_output(self, results: dict):
        """åˆ†ææœ€ç»ˆè¾“å‡º"""
        print(f"\nğŸ“Š Step 5: Final Output Analysis")
        
        pixel_values = results["pixel_values"]
        image_sizes = results["image_sizes"]
        
        print(f"   Final pixel_values shape: {pixel_values.shape}")
        print(f"   Data type: {pixel_values.dtype}")
        print(f"   Image sizes tensor: {image_sizes}")
        print(f"   Image sizes shape: {image_sizes.shape if image_sizes is not None else 'None'}")
        
        # å†…å­˜ä½¿ç”¨åˆ†æ
        num_elements = pixel_values.numel()
        memory_mb = num_elements * 4 / (1024 * 1024)  # å‡è®¾float32
        print(f"   Total elements: {num_elements:,}")
        print(f"   Approximate memory: {memory_mb:.2f} MB")
        
        # æ•°æ®åˆ†å¸ƒåˆ†æ
        print(f"\n   ğŸ“ˆ Data Distribution:")
        print(f"   Global mean: {pixel_values.mean().item():.6f}")
        print(f"   Global std: {pixel_values.std().item():.6f}")
        print(f"   Global min: {pixel_values.min().item():.6f}")
        print(f"   Global max: {pixel_values.max().item():.6f}")
    
    def visualize_processing_steps(self, image: Image.Image, save_path: str = None):
        """å¯è§†åŒ–å¤„ç†æ­¥éª¤"""
        print(f"\nğŸ¨ Step 6: Visualization")
        
        # è·å–å¤„ç†ç»“æœ
        processed_inputs = self.image_processor(image, return_tensors="pt")
        pixel_values = processed_inputs["pixel_values"]
        
        if len(pixel_values.shape) == 5:
            batch, num_scales, channels, height, width = pixel_values.shape
            
            # åˆ›å»ºå­å›¾
            fig, axes = plt.subplots(2, 3, figsize=(15, 10))
            fig.suptitle(f'LlavaNext Multi-scale Processing\nOriginal: {image.size} â†’ Processed: {num_scales} scales of {height}Ã—{width}', 
                        fontsize=14)
            
            # æ˜¾ç¤ºåŸå§‹å›¾åƒ
            axes[0, 0].imshow(image)
            axes[0, 0].set_title(f'Original Image\n{image.size}')
            axes[0, 0].axis('off')
            
            # æ˜¾ç¤ºå‰5ä¸ªå°ºåº¦
            for scale_idx in range(min(5, num_scales)):
                row = (scale_idx + 1) // 3
                col = (scale_idx + 1) % 3
                
                # è½¬æ¢tensorä¸ºå¯æ˜¾ç¤ºæ ¼å¼
                scale_tensor = pixel_values[0, scale_idx]  # [C, H, W]
                
                # åå½’ä¸€åŒ–ï¼ˆå‡è®¾ä½¿ç”¨ImageNetæ ‡å‡†åŒ–ï¼‰
                mean = torch.tensor([0.48145466, 0.4578275, 0.40821073]).view(3, 1, 1)
                std = torch.tensor([0.26862954, 0.26130258, 0.27577711]).view(3, 1, 1)
                
                unnormalized = scale_tensor * std + mean
                unnormalized = torch.clamp(unnormalized, 0, 1)
                
                # è½¬æ¢ä¸ºHWCæ ¼å¼ç”¨äºæ˜¾ç¤º
                img_to_show = unnormalized.permute(1, 2, 0).numpy()
                
                axes[row, col].imshow(img_to_show)
                axes[row, col].set_title(f'Scale {scale_idx}\n{height}Ã—{width}')
                axes[row, col].axis('off')
            
            plt.tight_layout()
            
            if save_path:
                plt.savefig(save_path, dpi=150, bbox_inches='tight')
                print(f"   Visualization saved to: {save_path}")
            else:
                plt.show()
        
        print(f"   âœ… Visualization completed")
    
    def compare_with_simple_resize(self, image: Image.Image):
        """å¯¹æ¯”ç®€å•resizeå’ŒLlavaNextå¤„ç†çš„å·®å¼‚"""
        print(f"\nğŸ” Step 7: Comparison with Simple Resize")
        
        # LlavaNextå¤„ç†
        llava_result = self.image_processor(image, return_tensors="pt")
        llava_pixel_values = llava_result["pixel_values"]
        
        # ç®€å•resizeå¤„ç†
        simple_resized = image.resize((336, 336))
        simple_array = np.array(simple_resized).transpose(2, 0, 1)  # HWC -> CHW
        simple_tensor = torch.tensor(simple_array, dtype=torch.float32) / 255.0
        
        # åº”ç”¨å½’ä¸€åŒ–
        mean = torch.tensor([0.48145466, 0.4578275, 0.40821073]).view(3, 1, 1)
        std = torch.tensor([0.26862954, 0.26130258, 0.27577711]).view(3, 1, 1)
        simple_normalized = (simple_tensor - mean) / std
        simple_final = simple_normalized.unsqueeze(0).unsqueeze(0)  # æ·»åŠ batchå’Œscaleç»´åº¦
        
        print(f"   LlavaNext shape: {llava_pixel_values.shape}")
        print(f"   Simple resize shape: {simple_final.shape}")
        
        print(f"\n   ğŸ“Š Statistical Comparison:")
        print(f"   LlavaNext - mean: {llava_pixel_values.mean():.6f}, std: {llava_pixel_values.std():.6f}")
        print(f"   Simple resize - mean: {simple_normalized.mean():.6f}, std: {simple_normalized.std():.6f}")
        
        print(f"\n   ğŸ’¡ Key Differences:")
        print(f"   - LlavaNext: Multi-scale processing ({llava_pixel_values.shape[1]} scales)")
        print(f"   - Simple: Single scale processing")
        print(f"   - LlavaNext: Adaptive resolution selection")
        print(f"   - Simple: Fixed 336Ã—336 resize")


def main():
    """ä¸»å‡½æ•°ï¼šè¿è¡Œå®Œæ•´åˆ†æ"""
    # åˆ›å»ºåˆ†æå™¨
    analyzer = ImageProcessorAnalysis()
    
    # åˆ›å»ºä¸€ä¸ªç¤ºä¾‹å›¾åƒ (1100, 808)
    # ä½ å¯ä»¥æ›¿æ¢ä¸ºå®é™…çš„å›¾åƒè·¯å¾„
    example_image = Image.new('RGB', (1100, 808), color='red')
    # æˆ–è€…ä½¿ç”¨å®é™…å›¾åƒï¼š
    # example_image = Image.open("path/to/your/image.jpg")
    
    print("ğŸš€ Starting LlavaNext Image Processor Analysis")
    print(f"ğŸ“ This analysis shows how an image of size (1100, 808) becomes pixel_values [1, 5, 3, 336, 336]")
    
    # è¿è¡Œå®Œæ•´åˆ†æ
    results = analyzer.analyze_full_pipeline(example_image)
    
    # å¯è§†åŒ–å¤„ç†æ­¥éª¤
    # analyzer.visualize_processing_steps(example_image)
    
    # å¯¹æ¯”åˆ†æ
    analyzer.compare_with_simple_resize(example_image)
    
    print("\n" + "=" * 80)
    print("ğŸ‰ Analysis completed!")
    print("=" * 80)


if __name__ == "__main__":
    main()